# Azure OpenAI Starter Python and TypeScript Examples

Complete guide to using your deployed Azure OpenAI **GPT-5-mini** model with the **Responses API** in **Python** and **TypeScript/Node.js**.

## About the Responses API

The Responses API is the newer, cleaner interface designed specifically for GPT-5-mini and other reasoning models. It provides:

- **Simpler syntax**: Uses `input` parameter instead of `messages`
- **Better for reasoning**: Optimized for GPT-5-mini's internal reasoning capabilities
- **Cleaner output**: Direct access to response text via `output_text`
- **Token visibility**: Clear visibility into reasoning tokens vs output tokens

## Prerequisites

‚úÖ Azure OpenAI GPT-5-mini deployed (run `azd up` first)  
‚úÖ Python 3.8+ or Node.js 18+ installed

## Quick Setup

### 1. Get Your Deployment Information
```bash
# Get all deployment details
azd env get-values

# Note these key values:
# AZURE_ENV_NAME=XXXXXX
# AZURE_OPENAI_ENDPOINT=https://openai-XXXXXX.openai.azure.com/
# AZURE_OPENAI_NAME=openai-XXXXXX  
# AZURE_OPENAI_GPT_DEPLOYMENT_NAME=gpt-5-mini
```

### 2. Get Your API Key
```bash
# Use env values from step 1
az cognitiveservices account keys list --name AZURE_OPENAI_NAME --resource-group rg-AZURE_ENV_NAME
# Copy key1 or key2 from the output
```
**Don't have Azure CLI?** Install it: https://learn.microsoft.com/en-us/cli/azure/install-azure-cli

## Python Client

### 3a. Install Dependencies & Run (Python)
```bash
# Navigate to Python example
cd src/python

# Install dependencies
pip install -r requirements.txt

# Set your credentials (replace with your actual values)
$env:AZURE_OPENAI_ENDPOINT="https://openai-XXXXXX.openai.azure.com/"
$env:AZURE_OPENAI_API_KEY="your-api-key-here"

# Run the example
python responses_example.py
```

## TypeScript/Node.js Client

### 3b. Install Dependencies & Run (TypeScript/Node.js)  
```bash
# Navigate to TypeScript example
cd src/typescript

# Install dependencies
npm run install-deps
# or manually: npm install openai tsx typescript @types/node

# Set your credentials (replace with your actual values)
$env:AZURE_OPENAI_ENDPOINT="https://openai-XXXXXX.openai.azure.com/"
$env:AZURE_OPENAI_API_KEY="your-api-key-here"

# Run the example
npm start
# or: npx tsx responses_example.ts
```

### 6. Test the Connection
   ```bash
   python client_example.py
   ```

## Expected Output

## Example Output

When you run either example, you should see:

```
üîó Connecting to: https://openai-xxx.openai.azure.com/openai/v1/
ü§ñ Testing GPT-5-mini model...
------------------------------------------------------------
‚úÖ Success! GPT-5-mini response:
--------------------------------------------------
Hello! I'm GPT-5-mini running on Microsoft Azure in Sweden Central. 

Something interesting about Sweden: Sweden has a unique concept called "allemansr√§tten" (the Right to Roam), which gives everyone the legal right to access and enjoy nature freely - you can walk, camp, pick berries, and mushrooms almost anywhere in the country, as long as you don't disturb wildlife or private property. This reflects Sweden's deep cultural connection to nature and trust-based society.
--------------------------------------------------
üìä Model: gpt-5-mini-2025-08-07
üìä Tokens used: 284
üìä Input tokens: 45
üìä Output tokens: 239
üìä Reasoning tokens: 156

üß† Testing with a more complex prompt that requires visible output...
------------------------------------------------------------
‚úÖ Complex response test:
------------------------------
Sweden is distinctive for its blend of social-democratic institutions and strong culture of innovation that has produced globally influential companies. Its unique combination of vast, accessible nature and progressive environmental policies fosters sustainability and a high quality of life.
------------------------------
üìä Complex test tokens: 396
üìä Complex reasoning tokens: 256

üéâ GPT-5-mini is working perfectly!
```

## Key Features

‚úÖ **GPT-5-mini (2025-08-07)** - Latest reasoning model from OpenAI  
‚úÖ **New v1 API** - No api-version needed, future-proof  
‚úÖ **Sweden Central** deployment - Optimal European region  
‚úÖ **Standard OpenAI client** - Works with Python and TypeScript  
‚úÖ **Minimal dependencies** - Just one package install  
‚úÖ **No containers** - Direct API calls, no complex setup  

## Code Examples

### Python - Basic Responses API
```python
from openai import OpenAI
import os

client = OpenAI(
    api_key=os.getenv("AZURE_OPENAI_API_KEY"),
    base_url=f"{os.getenv('AZURE_OPENAI_ENDPOINT')}/openai/v1/"
)

response = client.responses.create(
    model="gpt-5-mini",
    input="Explain quantum computing in simple terms",
    max_output_tokens=1000
)
print(response.output_text)
```

### TypeScript - Basic Responses API
```typescript
import OpenAI from 'openai';

const client = new OpenAI({
    apiKey: process.env.AZURE_OPENAI_API_KEY,
    baseURL: `${process.env.AZURE_OPENAI_ENDPOINT}/openai/v1/`
});

const response = await client.responses.create({
    model: "gpt-5-mini",
    input: "Explain quantum computing in simple terms",
    maxOutputTokens: 1000
});
console.log(response.outputText);
```

### Python - Conversation Format
```python
# The Responses API also supports conversation format
response = client.responses.create(
    model="gpt-5-mini",
    input=[
        {"role": "system", "content": "You are an Azure cloud architect."},
        {"role": "user", "content": "Design a scalable web application architecture."}
    ],
    max_output_tokens=1000
)
print(response.output_text)
```

### TypeScript - Conversation Format
```typescript
const response = await client.responses.create({
    model: "gpt-5-mini",
    input: [
        { role: "system", content: "You are an Azure cloud architect." },
        { role: "user", content: "Design a scalable web application architecture." }
    ],
    maxOutputTokens: 1000
});
console.log(response.outputText);
```

### Python - Accessing Reasoning Tokens
```python
# GPT-5-mini uses internal reasoning - you can see how many reasoning tokens were used
response = client.responses.create(
    model="gpt-5-mini",
    input="Explain quantum computing in simple terms",
    max_output_tokens=1000
)
print(response.output_text)
print(f"Reasoning tokens: {response.usage.output_tokens_details.reasoning_tokens}")
```

### TypeScript - Accessing Reasoning Tokens
```typescript
// GPT-5-mini uses internal reasoning - you can see how many reasoning tokens were used
const response = await client.responses.create({
    model: "gpt-5-mini",
    input: "Explain quantum computing in simple terms",
    maxOutputTokens: 1000
});
console.log(response.outputText);
console.log(`Reasoning tokens: ${response.usage?.outputTokensDetails?.reasoningTokens}`);
```

### Python - Accessing Reasoning Tokens
```python
# GPT-5-mini uses internal reasoning - you can see the token usage
response = client.responses.create(
    model="gpt-5-mini",
    input="Solve this step by step: 15 + 27 - 8 = ?",
    max_output_tokens=500
)

# Access reasoning and output tokens
print(f"Response: {response.output_text}")
print(f"Reasoning tokens: {response.usage.reasoning_tokens}")
print(f"Output tokens: {response.usage.output_tokens}")
print(f"Total tokens: {response.usage.total_tokens}")
```

### TypeScript - Accessing Reasoning Tokens
```typescript
// GPT-5-mini uses internal reasoning - you can see the token usage
const response = await client.responses.create({
    model: "gpt-5-mini",
    input: "Solve this step by step: 15 + 27 - 8 = ?",
    max_output_tokens: 500
});

// Access reasoning and output tokens
console.log(`Response: ${response.output_text}`);
console.log(`Reasoning tokens: ${response.usage?.reasoning_tokens}`);
console.log(`Output tokens: ${response.usage?.output_tokens}`);
console.log(`Total tokens: ${response.usage?.total_tokens}`);
```

### Python - Multi-Turn Conversation
```python
# Build a conversation with Responses API
messages = [
    {"role": "system", "content": "You are a helpful coding assistant."},
    {"role": "user", "content": "Write a Python function to calculate factorial"}
]

response = client.responses.create(
    model="gpt-5-mini",
    input=messages,
    max_output_tokens=400
)

# Add assistant's response to conversation
messages.append({"role": "assistant", "content": response.output_text})

# Continue the conversation
messages.append({"role": "user", "content": "Now optimize it with memoization"})

response2 = client.responses.create(
    model="gpt-5-mini",
    input=messages,
    max_output_tokens=400
)
print(response2.output_text)
```

### TypeScript - Multi-Turn Conversation
```typescript
// Build a conversation with Responses API
const messages: Array<{role: string, content: string}> = [
    { role: "system", content: "You are a helpful coding assistant." },
    { role: "user", content: "Write a TypeScript function to calculate factorial" }
];

const response = await client.responses.create({
    model: "gpt-5-mini",
    input: messages,
    max_output_tokens: 400
});

// Add assistant's response to conversation
messages.push({ role: "assistant", content: response.output_text ?? "" });

// Continue the conversation
messages.push({ role: "user", content: "Now optimize it with memoization" });

const response2 = await client.responses.create({
    model: "gpt-5-mini",
    input: messages,
    max_output_tokens: 400
});
console.log(response2.output_text);
```

## Troubleshooting

**‚ùå "Missing environment variables"**  
‚Üí Run `azd env get-values` to get your endpoint  
‚Üí Get API key: `az cognitiveservices account keys list --name YOUR_RESOURCE_NAME --resource-group rg-YOUR_ENV_NAME`

**‚ùå "Invalid request" or 401 errors**  
‚Üí Verify your API key is correct  
‚Üí Check endpoint URL includes trailing slash: `https://openai-xxx.openai.azure.com/`

**‚ùå "Model not found"**  
‚Üí Ensure deployment completed: `azd env get-values` should show `AZURE_OPENAI_GPT_DEPLOYMENT_NAME=gpt-5-mini`  
‚Üí Check deployment status in Azure portal

**‚ùå "Rate limit exceeded"**  
‚Üí Default capacity is 10K tokens per minute  
‚Üí Wait and retry, or increase capacity in Azure portal

## Why the New v1 API?

This template uses Azure OpenAI's **new v1 API endpoint** which:

‚úÖ Uses standard `OpenAI()` client instead of `AzureOpenAI()`  
‚úÖ No `api_version` parameter needed - future-proof  
‚úÖ Same client code works for both OpenAI and Azure OpenAI  
‚úÖ Automatic compatibility with latest OpenAI features  
‚úÖ Simplified authentication and configuration  

## About the Responses API

This template uses the **Responses API**, which provides a cleaner interface optimized for GPT-5-mini reasoning models:

**Key Benefits:**
- ‚úÖ Simpler interface - direct `input` parameter instead of message formatting
- ‚úÖ Direct access to reasoning tokens via `response.usage.output_tokens_details.reasoning_tokens`
- ‚úÖ Supports both simple text and conversation format
- ‚úÖ Designed for reasoning models like GPT-5-mini
- ‚úÖ Cleaner response structure with `output_text` property

**Important:** Use `max_output_tokens=1000` (not 50-200) to account for GPT-5-mini's internal reasoning process. The model uses reasoning tokens internally before generating the final output.

## EntraID Authentication (Recommended for Production)

Instead of using API keys, you can use **Azure Identity (EntraID)** for more secure, keyless authentication:

### Python - EntraID Authentication
```python
from openai import OpenAI
from azure.identity import DefaultAzureCredential, get_bearer_token_provider

# Use Azure Identity for authentication
token_provider = get_bearer_token_provider(
    DefaultAzureCredential(),
    "https://cognitiveservices.azure.com/.default"
)

# Use standard OpenAI client with Azure endpoint and token provider
client = OpenAI(
    base_url=f"{os.getenv('AZURE_OPENAI_ENDPOINT')}openai/v1/",
    api_key=token_provider
)

# Use the Responses API normally
response = client.responses.create(
    model="gpt-5-mini",
    input="Explain quantum computing in simple terms",
    max_output_tokens=1000
)
print(response.output_text)
```

### TypeScript - EntraID Authentication
```typescript
import OpenAI from "openai";
import { DefaultAzureCredential, getBearerTokenProvider } from "@azure/identity";

// Use Azure Identity for authentication
const credential = new DefaultAzureCredential();
const scope = "https://cognitiveservices.azure.com/.default";
const tokenProvider = getBearerTokenProvider(credential, scope);

// Use standard OpenAI client with Azure endpoint and token provider
const client = new OpenAI({
    baseURL: `${process.env.AZURE_OPENAI_ENDPOINT}openai/v1/`,
    apiKey: tokenProvider as any  // Token provider acts as dynamic API key
});

// Use the Responses API normally
const response = await client.responses.create({
    model: "gpt-5-mini",
    input: "Explain quantum computing in simple terms",
    max_output_tokens: 1000
});
console.log(response.output_text);
```

### Run EntraID Examples
```bash
# Python
cd src/python && python responses_example_entra.py

# TypeScript
cd src/typescript && tsx responses_example_entra.ts
```

**Benefits of EntraID Authentication:**
- ‚úÖ No API keys to manage or rotate
- ‚úÖ Uses your Azure CLI login or Managed Identity
- ‚úÖ Better security with Azure RBAC
- ‚úÖ Automatic token refresh
- ‚úÖ Works with service principals and managed identities

**Setup Requirements:**
1. Install dependencies: `pip install azure-identity` or `npm install @azure/identity`
2. Login to Azure: `az login`
3. Assign the "Cognitive Services OpenAI User" role to yourself:
   ```bash
   # Get your Azure AD user ID
   $userId = az ad signed-in-user show --query id -o tsv
   
   # Get the OpenAI resource ID
   $resourceId = azd env get-values | Select-String 'AZURE_OPENAI_ENDPOINT' | ForEach-Object { 
       $endpoint = $_ -replace 'AZURE_OPENAI_ENDPOINT="(.*)"', '$1'
       $name = ($endpoint -split '\.')[0] -replace 'https://', ''
       az cognitiveservices account show --name $name --resource-group (azd env get-values | Select-String 'AZURE_ENV_NAME' | ForEach-Object { "rg-" + ($_ -replace 'AZURE_ENV_NAME="(.*)"', '$1') }) --query id -o tsv
   }
   
   # Assign the role
   az role assignment create --role "Cognitive Services OpenAI User" --assignee $userId --scope $resourceId
   ```

## Next Steps

üîß **Customize the examples**: Edit `responses_example.py` or `responses_example.ts` for your use case  
üìö **Learn more**: [Azure OpenAI documentation](https://learn.microsoft.com/azure/ai-services/openai/)  
üöÄ **Add more models**: Edit `infra/resources.bicep` to deploy additional models  
‚ö° **Scale up**: Increase capacity or try GPT-5 full model  

---

**üéâ You're now running GPT-5-mini on Azure!** Experience the future of AI reasoning.
